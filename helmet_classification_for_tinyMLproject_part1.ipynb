{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "helmet_classification_for_tinyMLproject_part1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "VxbyIP98UOoz",
        "_x0en3V-blmN",
        "Mu9c78aFjwml",
        "qpgtpT6Tj0rl",
        "yYSL68SZj3q6",
        "MoVlH1-g8qwP",
        "VY8r-nJJGNSV",
        "LqxsRBqmhGsz",
        "7LhHAwpTG1tO",
        "H7k06--WKJ6V",
        "qEARyat3Iydo",
        "xOa3G3PjKIYC",
        "FW0eNSv3I1fu",
        "gFRMhTo-l3qT",
        "3O6W6vx3Gcqk",
        "eXaVcO0cj6V3"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxbyIP98UOoz",
        "colab_type": "text"
      },
      "source": [
        "# Helmet Classification For TinyML Project\n",
        "\n",
        "> 이 notebook 은 open source 컨트리뷰톤 2020 - tinyML (Tensorflow Lite Project) Mobility Team 의 오픈소스 프로젝트를 위해 만들어졌습니다. \n",
        "\n",
        "- 모빌리티 팀 (멘토 맹윤호)\n",
        "- 최예진(팀장), 이민우, 전수민, 이장후, 이경환, 조승현\n",
        "- **.ipynb 제작 - 이장후. 2020/08/25**\n",
        "- **.ipynb 수정자 -**\n",
        "\n",
        "<br>\n",
        "\n",
        "- Target Github Repository : [TinyML : Tensorflow lite for microcontroller](https://github.com/yunho0130/tensorflow-lite)\n",
        "- Team Github Repository : [TinyML-Mobility](https://github.com/orgs/tinyml-mobility/teams)\n",
        "\n",
        "<br>\n",
        "\n",
        "## Before We Start\n",
        "- 런타임 -> GPU 로 변경 하셨나요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yC8JXqNghoE",
        "colab_type": "text"
      },
      "source": [
        "# Google Drive\n",
        "\n",
        "- 학습을 시키기 전 데이터가 있는 google Drive 와 연동을 해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZfIohGzavab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "abe49462-83c4-4267-e282-3ae6f9ecc763"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRqsMIdWgm6A",
        "colab_type": "text"
      },
      "source": [
        "## Include Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3kyAsKGbKfZ",
        "colab_type": "text"
      },
      "source": [
        "- 이 노트북의 소스코드는 tensorflow 2.0 이상과 호환되지 않습니다.\n",
        "- Google colab 에서는 %tensorflow_version 을 통해, 원하는 버전의 tensorflow 를 쉽게 불러올 수 있습니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcV5KCk6a5Ey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "149c97fe-41a5-4cf2-a10a-d47434f4f8af"
      },
      "source": [
        "try:\n",
        "  # This %tensorflow_version magic only works in Colab.\n",
        "  %tensorflow_version 1.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "# For your non-Colab code, be sure you have tensorflow==1.15\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('1')\n",
        "\n",
        "# tf.enable_eager_execution() 테스트 안 해봄.\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD2Q4nwnbGmw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2107d744-80ac-4e4a-eecd-8ef9102a79ee"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.15.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vbg-RZNWk9a",
        "colab_type": "text"
      },
      "source": [
        "## Serve Data\n",
        "- 헬멧 미착용 데이터셋 : https://drive.google.com/file/d/1WYZV_UTPvjv16Z57uMm_kBSWAYJoI3jk/view?usp=sharing\n",
        "- 헬멧 착용 데이터셋 : https://drive.google.com/file/d/1SrN8LPwvlTttmxJQMDBgDNs_nYpqMOxw/view?usp=sharing\n",
        "- 위 데이터들을 모두 자신의 구글 드라이브에 올려 둡시다.\n",
        "- 구글 드라이브에게 '바탕화면' 같은 존재는 ```/content/gdrive/\"My Drive\"/``` 입니다.\n",
        "- 저의 경우 위 압축 파일들을 ```/content/gdrive/\"My Drive\"/data/``` 에 넣어 두겠습니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### Zip 압축 풀기\n",
        "- linux 에서 zip 파일의 압축을 풀기 위해서는, unzip 명령을 사용합니다. Google Colab 에서는, ! 를 이용해서 리눅스 명령어를 호출할 수 있습니다.\n",
        "- 이때, 리눅스 명령이 수행되는 위치는, 현재 위치입니다. 현재 위치는 !ls 를 통해 조회할 수 있습니다.\n",
        "- %cd 를 통해, 현재 위치를 이동할 수 있습니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "현재 위치를 조회합니다. <br>\n",
        "```!ls```\n",
        "\n",
        "<br>\n",
        "\n",
        "압축파일이 있는 해당 위치로 이동합니다. <br>\n",
        "```%cd /content/gdrive/\"My Drive\"/data/```\n",
        "\n",
        "<br>\n",
        "\n",
        "압축을 해제합니다. <br>\n",
        "```!unzip <파일명>.zip -d <압축을 풀 폴더>```\n",
        "\n",
        "<br>\n",
        "\n",
        "약간의 시간이 소요됩니다. <br>\n",
        "\n",
        "<br>\n",
        "\n",
        "여담 <br>\n",
        "> 프로젝트를 진행하다가, ls 와 cd 모두 linux 명령인데 왜 cd 는 % 를 사용하고 ls 는 ! 를 사용하는지 궁금할 수 있습니다. 정확히 말하면, % 는 google colab 에서 특정한 목적을 가지고 제공되는 기능으로, magic 이라고 합니다. 반면 ! 는 순수 linux 명령어입니다. !cd 를 이용해서 경로를 이동할 수 있으나, 그 경로가 유지되지 않고 원래대로 돌아와 버립니다. 따라서 cd 를 이용해서 경로 작업을 할 때에는 % 를 사용해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpCCroKgWj9n",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "!ls\n",
        "%cd /content/gdrive/\"My Drive\"/data/\n",
        "\n",
        "# 혹시 이전에 스크립트릴 실행했을 수 있으니, 다시 실행시키려면 그 전에 미리 잘 지워줍시다.\n",
        "!rm -r helmetclassification \n",
        "\n",
        "# 경로들을 만들어 줍시다.\n",
        "!mkdir helmetclassification\n",
        "!mkdir helmetclassification/helmet\n",
        "!mkdir helmetclassification/non_helmet\n",
        "\n",
        "# 압축 해제!\n",
        "!unzip helmet_crop.zip -d /content/gdrive/\"My Drive\"/data/helmetclassification/helmet\n",
        "!unzip not_wearing_a_helmet.zip -d /content/gdrive/\"My Drive\"/data/helmetclassification/non_helmet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi1C99JBgves",
        "colab_type": "text"
      },
      "source": [
        "## Hyper Parameters\n",
        "- 하이퍼파라미터들을 위에 모아서 정의해두는 습관\n",
        "- google colab 에서는 아까 언급했던 % magic 을 이용해서 tensorboard 를 쉽게 사용할 수 있도록 만들어 두었습니다. (그런데 잘 돌아가지는 않음)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsqrbpKteFLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKf4BLAFbcz7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "dc65f2fa-eca0-4fc7-aa38-b7107470bb22"
      },
      "source": [
        "%cd /content/gdrive/\"My Drive\"/data/\n",
        "\n",
        "# 데이터가 존재하는 경로 ( /content/gdrive/\"My Drive\"/data/helmetclassification ) 를 data_dir 변수에 저장합니다.\n",
        "data_dir = os.path.join(os.getcwd(), 'helmetclassification')\n",
        "print(data_dir)\n",
        "\n",
        "# input 이미지의 크기는 224 by 224 by 3 으로 상정합니다. 채널은 RGB 이므로, 3 입니다.\n",
        "IMG_WIDTH = 224\n",
        "IMG_HEIGHT = 224\n",
        "IMG_CHANNEL = 3\n",
        "IMG_SHAPE = (IMG_WIDTH, IMG_HEIGHT, IMG_CHANNEL)\n",
        "\n",
        "# 연산 처리 단위 (배치) 는 이미지 16장, 그리고 Learning Rate, optimizer, 에폭 등을 설정합니다.\n",
        "# *참고* : Optimizer 에서 SGD 는 최근 잘 사용하지 않지만, 안정적인 수렴을 위해 특정 경우에 사용합니다. \n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE_SGD = 0.001\n",
        "LEARNING_RATE_ADAM = 0.0001\n",
        "TRAINING_OPTIMIZER_SGD  = tf.keras.optimizers.SGD(learning_rate=LEARNING_RATE_SGD, momentum=0.0)\n",
        "TRAINING_OPTIMIZER_ADAM = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_ADAM)\n",
        "EPOCHS = 3\n",
        "\n",
        "# 우리는 h5 file 을 tflite 파일로 전환할 것입니다. 이름을 미리 정해 둡시다.\n",
        "SAVED_KERAS_MODEL_NAME = 'helmet_classification_model.h5'\n",
        "\n",
        "# 우리는 잠시 후에 라벨 파일을 만들어낼 것인데, 라벨 파일의 이름을 미리 정의해 둡시다.\n",
        "LABEL_FILE_NAME = 'ishelmetlabel.txt'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/data\n",
            "/content/gdrive/My Drive/data/helmetclassification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GemJq1CujkU9",
        "colab_type": "text"
      },
      "source": [
        "## Generator\n",
        "- python 에는 '제네레이터' 라는 것이 존재합니다.\n",
        "- 그 때 그 때, 상황에 맞는 데이터를 만들어 주는 역할을 수행합니다.\n",
        "- keras 에서는, 이를 이용하여, 우리가 가지고 있는 image data 들을 정갈하게 정리해서 하나씩 하나씩 필요에 맞게 넘겨 주는 함수를 만들어 두었습니다. \n",
        "\n",
        "<br>\n",
        "\n",
        "### ImageDataGenerator : Data Augmentation\n",
        "- Data Augmentation 은 말 그대로 데이터를 증폭시켜주는 역할을 합니다.\n",
        "- 고양이 사진이 있을 때, 고양이 머리만 있어도 고양이이고, 몸통만 있어도 고양이이며, 형광등 아래의 고양이도 고양이고, 백열등 아래의 고양이도 고양이입니다.\n",
        "- 우리가 가지고 있는 이미지를 인위적으로 변형한 뒤에도, 올바르게 추론할 수 있도록 이미지 데이터를 다양한 방법으로 변형시켜줄 수 있도록 돕는 함수가 Keras 의 ImageDataGenerator 입니다.\n",
        "- Train 할 때는 이미지를 변형해서 forward-pass 시켜주지만, test 를 할 때에는 이미지를 변형해서 네트워크를 통과시키면 안 되겠지요.\n",
        "- 다만, Train 이나 Test 시에는 Network 의 사양에 맞추어서 0~1 의 범위로 input 을 정규화 시켜 주어야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvEQ8ZedbJLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    rescale=1./255,\n",
        "    dtype='float',\n",
        "    fill_mode=\"nearest\",\n",
        "    horizontal_flip=True,\n",
        "    channel_shift_range=0.1, \n",
        "    rotation_range=20,\n",
        "    brightness_range=(-0.3, 0.3)\n",
        "    )\n",
        "\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    dtype='float',\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSX6i95pgq12",
        "colab_type": "text"
      },
      "source": [
        "## Train-Valid(Test-Validation) Data Split\n",
        "\n",
        "- keras 는 image classification 과 같은 간단한 문제들을 쉽게 해결할 수 있도록 돕기 위해 ```flow_from_directory``` 와 같은 함수를 제공합니다.\n",
        "- 위에서 만들었던 ImageDataGenerator() 을 거친 객체들을 ```flow_from_directory``` 에 대입하여 간단하게 클래스별로 학습을 시킬 수 있습니다.\n",
        "- 이때 Keras 는 미리 데이터를 '/train' 폴더와 '/test' 폴더로 나누어 놓기를 요구합니다.\n",
        "- 하지만 우리는 train data 와 test data 를 나누어두지 않았습니다. 이 경우에도, Keras 는 우리의 작업을 도와줄 수 있는 함수를 제공하지만, 해당 함수를 사용하면, Data Augmentation 을 정상적으로 수행할 수 없습니다.\n",
        "- 따라서, 우리가 직접 모은 데이터들을 train 과 test 폴더로 분리해서 담아 주는 스크립트를 작성해 봅시다.\n",
        "\n",
        "*Data Augmentation 과 train_test split 사이의 문제 : 궁금하신 분들은 참고 : [관련 이슈](https://stackoverflow.com/questions/53037510/can-flow-from-directory-get-train-and-validation-data-from-the-same-directory-in)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndiMiZvThUl4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2908d9d4-fce3-4637-db8d-0ae35133311c"
      },
      "source": [
        "# 현재 디렉터리 이동\n",
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/\n",
        "\n",
        "# /content/gdrive/\"My Drive\"/data/helmetclassification/ 에 train 과 test 폴더를 만들어 줍니다.\n",
        "!mkdir train\n",
        "!mkdir train/helmet\n",
        "!mkdir train/non_helmet\n",
        "!mkdir test\n",
        "!mkdir test/helmet\n",
        "!mkdir test/non_helmet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/data/helmetclassification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKEWWrOJZ7mW",
        "colab_type": "text"
      },
      "source": [
        "### Wearing Helmet Data\n",
        "- test 데이터 랜덤하게 뽑아내기\n",
        "- 뽑은 데이터 test 폴더로 옮겨주기\n",
        "- 나머지 데이터를 train 폴더로 옮기기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzOGLIFjkh8L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "348c84f3-74aa-45fb-b20a-8aea13b3d84b"
      },
      "source": [
        "# /content/gdrive/\"My Drive\"/data/helmetclassification/helmet 경로부터 작업해 줍시다.\n",
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/helmet\n",
        "\n",
        "helmet_data_directory = os.getcwd()\n",
        "file_list = os.listdir(helmet_data_directory)\n",
        "print('Count of file :', len(file_list))\n",
        "\n",
        "import random\n",
        "sampled_helmet_file_list = random.sample(file_list, int(len(file_list) * 0.4))\n",
        "print('Count of sampled file :', len(sampled_helmet_file_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/data/helmetclassification/helmet\n",
            "Count of file : 12772\n",
            "Count of sampled file : 5108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeE6WeZnmDhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이제 sample 된 데이터를 /content/gdrive/\"My Drive\"/data/helmetclassification/test/helmet 으로 옮겨 줄 차례입니다.\n",
        "import shutil\n",
        "target_dir = os.path.join(os.path.join(data_dir, 'test'), 'helmet')\n",
        "for f in sampled_helmet_file_list :\n",
        "  current_file = os.path.join(helmet_data_directory, f)\n",
        "  shutil.move(current_file, os.path.join(target_dir, f))\n",
        "  print(current_file,'\\t->\\t',os.path.join(target_dir, f))\n",
        "\n",
        "# 이제 test 데이터를 모두 옮겼으니, train 데이터도 모두 옮겨 줍시다.\n",
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/\n",
        "!mv helmet/ train/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px_BlwjVZ_Y1",
        "colab_type": "text"
      },
      "source": [
        "### Not Wearing Helmet Data\n",
        "- test 데이터 랜덤하게 뽑아내기\n",
        "- 뽑은 데이터 test 폴더로 옮겨주기\n",
        "- 나머지 데이터를 train 폴더로 옮기기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FYuZtyak1fA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e752247a-0d4d-4f65-a466-54b8e84f5481"
      },
      "source": [
        "# /content/gdrive/\"My Drive\"/data/helmetclassification/non_helmet 경로를 작업할 차례입니다.\n",
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/non_helmet\n",
        "\n",
        "# 해당 경로는, 다양한 경로로부터 사람의 이미지를 취득했기에, 이를 모두 모아주는 작업이 필요합니다.\n",
        "file_list = os.listdir(os.getcwd())\n",
        "print(file_list)\n",
        "\n",
        "# 내부에 MACOS 용 파일과 자잘한 더미 파일이 존재하니 이를 제거해 줍니다.\n",
        "!rm -r __MACOSX\n",
        "!rm ./pedestrian/.DS_Store\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/data/helmetclassification/non_helmet\n",
            "['face_1-1500', '__MACOSX', 'face_1500-5000', 'pedestrian']\n",
            "face_1-1500  face_1500-5000  pedestrian\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loZJArDddq1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/non_helmet\n",
        "\n",
        "file_list = []\n",
        "for (root, dirs, files) in os.walk(os.getcwd()):\n",
        "  print(\"root : \" + root)\n",
        "  if len(files) > 0:\n",
        "    for file_name in files:\n",
        "      if file_name[-3:] in ['jpg', 'png'] :\n",
        "        file_full_path = os.path.join(root, file_name)\n",
        "        print('append to file_list : ', file_full_path)\n",
        "        file_list.append(file_full_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KokVJakP_5jS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23d0e394-9894-4e58-a543-b650b87cc311"
      },
      "source": [
        "import random\n",
        "sampled_nonhelmet_file_list = random.sample(file_list, int(len(file_list) * 0.4))\n",
        "print('Count of sampled file :', len(sampled_nonhelmet_file_list), 'out of', len(file_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of sampled file : 2360 out of 5901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPSTmG5HlQgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이제 sample 된 데이터를 /content/gdrive/\"My Drive\"/data/helmetclassification/test/helmet 으로 옮겨 줄 차례입니다.\n",
        "import shutil\n",
        "target_dir = os.path.join(os.path.join(data_dir, 'test'), 'non_helmet')\n",
        "for cnt, f in enumerate(sampled_nonhelmet_file_list) :\n",
        "  # 새로운 임시 이름 (cnt) + 확장자 (.xxx) 로 새로운 이름을 부여\n",
        "  postfix = str(cnt) + f[-4:] \n",
        "  shutil.move(f, os.path.join(target_dir, postfix))\n",
        "  print('[test data]', f,'\\t->\\t',os.path.join(target_dir, postfix))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehT0SCzSfRBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test 데이터를 모두 옮겼으니, train 데이터도 모두 옮겨 줍시다.\n",
        "cnt = 0\n",
        "target_dir = os.path.join(os.path.join(data_dir, 'train'), 'non_helmet')\n",
        "for f in file_list:\n",
        "  if os.path.isfile(f):\n",
        "    postfix = str(cnt) + f[-4:]\n",
        "    shutil.move(f, os.path.join(target_dir, postfix))\n",
        "    print('[train data]', f,'\\t->\\t',os.path.join(target_dir, postfix))\n",
        "    cnt += 1\n",
        "\n",
        "# 원래 존재하던 폴더를 지워 버립시다.\n",
        "# %cd /content/gdrive/\"My Drive\"/data/helmetclassification/\n",
        "# !rm -r non_helmet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWuBA7K_kkVN",
        "colab_type": "text"
      },
      "source": [
        "### Check Directory\n",
        "- 잘 정리되었나 확인해 봅시다\n",
        "- train, test 폴더만 남아 있어야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRWf-EcZkfXJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "bd21e703-dce9-4e72-d399-b72de8a361ca"
      },
      "source": [
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/\n",
        "!ls\n",
        "\n",
        "# helmet\n",
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/train/helmet/\n",
        "file_list = os.listdir(os.getcwd())\n",
        "print('count of train helmet file :', len(file_list))\n",
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/test/helmet/\n",
        "file_list = os.listdir(os.getcwd())\n",
        "print('count of test helmet file :', len(file_list))\n",
        "\n",
        "# non_helmet\n",
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/train/non_helmet/\n",
        "file_list = os.listdir(os.getcwd())\n",
        "print('Count of train non_helmet file :', len(file_list))\n",
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/test/non_helmet/\n",
        "file_list = os.listdir(os.getcwd())\n",
        "print('Count of test non_helmet file :', len(file_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/data/helmetclassification\n",
            "logs  non_helmet  test\ttrain\n",
            "/content/gdrive/My Drive/data/helmetclassification/train/helmet\n",
            "count of train helmet file : 7664\n",
            "/content/gdrive/My Drive/data/helmetclassification/test/helmet\n",
            "count of test helmet file : 5108\n",
            "/content/gdrive/My Drive/data/helmetclassification/train/non_helmet\n",
            "Count of train non_helmet file : 3541\n",
            "/content/gdrive/My Drive/data/helmetclassification/test/non_helmet\n",
            "Count of test non_helmet file : 2360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRCJMSXjqaZW",
        "colab_type": "text"
      },
      "source": [
        "## Data Generator Flow From Directory\n",
        "- Keras 는 Directory 이름과 해당 폴더로부터 알아서 클래스를 구분해주고, 쉽게 training 시킬 수 있도록 API 를 제공합니다.\n",
        "- train_generator : generator 로써, next() 수행 시 하나의 tensor 를 만들어냅니다.\n",
        "  - 한 번에 만들어내는 tensor 은 (image tensor, label tensor) 이고, 그 shape 은 (batch_size, 224, 224, 3)  (batch_size, 2 - 클래스가 2개이므로) 입니다.\n",
        "- val_generator : generator 로써, 이하동문.\n",
        "  - 한 번에 만들어내는 tensor 은 (image tensor, label tensor) 이고, 그 shape 은 (1, 224, 224, 3)  (1, 2) 입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZD0OId0gqQW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0822d103-8491-4d09-d14e-326f5a211194"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir+'/train',\n",
        "    color_mode=\"rgb\",\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    )\n",
        "\n",
        "val_generator = test_datagen.flow_from_directory(\n",
        "    data_dir+'/test',\n",
        "    color_mode=\"rgb\",\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    batch_size=1,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 11205 images belonging to 2 classes.\n",
            "Found 7468 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_x0en3V-blmN",
        "colab_type": "text"
      },
      "source": [
        "### Label 생성기\n",
        "- 우리가 데이터들을 (non_helmet, helmet) 클래스별로 train, test 로 나누고 깔끔하게 데이터를 전부 모아 두었으므로, 해당 폴더 이름으로부터 label 파일을 만들 수 있습니다.\n",
        "- label 파일이란, 모델이 추론한 결과가 어떤 클래스를 의미하는지 정보를 담고 있는 그냥 이름표 파일이라고 생각하면 됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cmVOrdEbiq9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "c85bb552-6102-4f78-fcde-9b5d1f84b9ee"
      },
      "source": [
        "# 디렉토리 이름을 라벨로 바로 써버리는 소스코드입니다.\n",
        "%cd /content/gdrive/\"My Drive\"/data/\n",
        "\n",
        "print(train_generator.class_indices) # type dictionary\n",
        "print(len(train_generator.class_indices))\n",
        "class_cnt = len(train_generator.class_indices)\n",
        "\n",
        "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "with open('{}'.format(LABEL_FILE_NAME), 'w') as f:\n",
        "  f.write(labels)\n",
        "\n",
        "!cat {LABEL_FILE_NAME}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/data\n",
            "{'helmet': 0, 'non_helmet': 1}\n",
            "2\n",
            "helmet\n",
            "non_helmet"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu9c78aFjwml",
        "colab_type": "text"
      },
      "source": [
        "# Model For training\n",
        "- 이제 모델을 만들고, 훈련을 시켜 보도록 합시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJvbokNJS4zr",
        "colab_type": "text"
      },
      "source": [
        "### 선택지1 : MobileNet V2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8eciMIMdhgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "1ab776c7-b4f9-4f27-9050-9d3f71515794"
      },
      "source": [
        "# Create the base model from the pre-trained MobileNet V2\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False, \n",
        "                                               # weights='imagenet'\n",
        "                                               # If, instead, you want to reuse the pretrained models (e.g.: by setting weights='imagenet' in the definition of MobileNetV2), then you should use the specific preprocessing in\n",
        "                                               )\n",
        "base_model.trainable = True"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdSNQ8icS9X7",
        "colab_type": "text"
      },
      "source": [
        "### 선택지2 : VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCe_TOPYS09C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IJQ-erNdxAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 뒷단에 추가 레이어\n",
        "full_model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(name = \"GAP\"),\n",
        "  # tf.keras.layers.Convolution2D(2, (1,1), strides=(1,1), activation='softmax', name='final_dense'),\n",
        "  tf.keras.layers.Dense(units=2, activation='softmax', name = \"final_dense\"),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYdqDWwSd2Be",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "c911de62-b9ac-4004-8c2c-3a2ffb55d2a1"
      },
      "source": [
        "full_model.compile(optimizer=TRAINING_OPTIMIZER_SGD, \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "full_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "mobilenetv2_1.00_224 (Model) (None, 7, 7, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "GAP (GlobalAveragePooling2D) (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "final_dense (Dense)          (None, 2)                 2562      \n",
            "=================================================================\n",
            "Total params: 2,260,546\n",
            "Trainable params: 2,226,434\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km22RN4C6M1n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "6382cf50-b066-43a4-97d4-92689c3f218e"
      },
      "source": [
        "dense_layer = full_model.layers[-1].get_weights()[0]\n",
        "gap_layer = full_model.layers[-2].output\n",
        "final_conv_layer = full_model.layers[-3].output\n",
        "print(type(dense_layer), type(gap_layer), type(final_conv_layer))\n",
        "print('dense layer W shape : ', dense_layer.shape)\n",
        "print('GAP layer output tensor shape : ', gap_layer.shape)\n",
        "print('final convolution layer output tensor shape : ', final_conv_layer.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> <class 'tensorflow.python.framework.ops.Tensor'> <class 'tensorflow.python.framework.ops.Tensor'>\n",
            "dense layer W shape :  (1280, 2)\n",
            "GAP layer output tensor shape :  (?, 1280)\n",
            "final convolution layer output tensor shape :  (?, 7, 7, 1280)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpgtpT6Tj0rl",
        "colab_type": "text"
      },
      "source": [
        "## Train\n",
        "- 모델을 다 만들었으니 이제 훈련을 시킬 차례입니다.\n",
        "- 그런데 훈련을 시작하게 되면, 개입이 불가능해집니다.\n",
        "- 따라서 특정 타이밍(예를 들어, 1에폭마다) 적절히 호출되는 콜백 함수를 미리 등록시켜 두고, 훈련을 시작하는 것이 바람직합니다.\n",
        "  - 중간중간 모델의 가중치를 세이브하는 기능\n",
        "  - 텐서보드로 로그를 전송하는 기능\n",
        "- 일반적으로 이 두 가지 기능을 callback 으로 등록시켜 두곤 합니다.\n",
        "- keras_model.fit_generator() 함수가 호출되면 Training 이 시작됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oym2hQx8f2XQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOvaEY-RSp9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"Start epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"End epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
        "\n",
        "    def on_test_batch_begin(self, batch, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        data = val_generator.next()\n",
        "        shape1 = data[0].shape\n",
        "        answer_shape1 = data[1].shape\n",
        "        dtype1 = data[0].dtype\n",
        "        print(\"...Evaluating: start of batch {}; shape {} - dtype {}, {}; got log keys: {}\\n\".format(batch, shape1, dtype1, answer_shape1, keys))\n",
        "\n",
        "    def on_predict_batch_begin(self, batch, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"...Predicting: start of batch {}; got log keys: {}\".format(batch, keys))\n",
        "\n",
        "    def on_predict_batch_end(self, batch, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"...Predicting: end of batch {}; got log keys: {}\".format(batch, keys))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZf5lLymd73I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification\n",
        "\n",
        "# 저장할 로그 파일의 이름을 준비합니다.\n",
        "log_dir = os.path.join(os.getcwd(), os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,     # 저장할 로그파일의 이름을 지정합니다.\n",
        "                                                      histogram_freq=1,    # 가중치나 이런 것들을 visualization 하는 histogram 을 그리는 작업을 1 epoch 마다 합니다. \n",
        "                                                      update_freq='epoch'\n",
        "                                                      ) # 1에폭마다 Tensorboard 를 갱신합니다.\n",
        "\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    os.path.join(data_dir, 'checkpoint'), monitor='val_loss', verbose=0, save_best_only=False,\n",
        "    save_weights_only=False, mode='auto', save_freq='epoch', options=None,\n",
        ")\n",
        "\n",
        "# 학습 시작. 변수 history 는 학습을 마친 뒤 학습중 있었던 일들을 볼 수 있도록 keras 에서 제공하는 객체입니다.\n",
        "history = full_model.fit_generator(train_generator, \n",
        "                    epochs=EPOCHS, \n",
        "                    validation_data=val_generator,\n",
        "                    callbacks=[\n",
        "                               tensorboard_callback, \n",
        "                               checkpoint_callback,\n",
        "                               CustomCallback()],\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYSL68SZj3q6",
        "colab_type": "text"
      },
      "source": [
        "## Estimate\n",
        "- train 의 과정과 결과를 보는 방법은, tensorboard 를 활용하는 방법도 있고, history 객체를 이용하는 방법도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDgJ0p8veNOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# history 객체 이용\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(19, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rUGp3sTjIBS",
        "colab_type": "text"
      },
      "source": [
        "### Estimate with Testset\n",
        "- 학습 과정에서의 변화를 관찰했다면, 이제 우리가 아직 사용하지 않은 test set 을 활용해서 학습 결과를 관찰해 보도록 합시다.\n",
        "- 제네레이터에서 제공되는 샘플로 평가할 때는 evaluate_generator 함수를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBgB97fPjHTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores  = tf.keras.evaluate_generator(\n",
        "  full_model,\n",
        "  val_generator,\n",
        "  steps = 100,\n",
        "  workers = 4,\n",
        "  callbacks = None\n",
        ")\n",
        "print(scores, \" % Accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkemHKX_jCde",
        "colab_type": "text"
      },
      "source": [
        "# Save Entire Model\n",
        "- keras 는 다시 keras 를 이용해서 쉽게 모델을 불러올 수 있도록 저장하는 API 를 가지고 있습니다.\n",
        "- 저장합시다!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEfYMSrYjCBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification\n",
        "entire_model.save(SAVED_KERAS_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9hFqjeBmN5N",
        "colab_type": "text"
      },
      "source": [
        "# Next Time (part2)\n",
        "수고했습니다! Part 2 에서는 다음과 같은 내용을 진행해 보도록 합시다.\n",
        "- keras 내장 모델인 mobilenet v2 를 불러오지 말고, 직접 mobilenet v2 를 구현해 봅시다.\n",
        "- 구현된 모델을 조금 수정하면서, Class Activation Map* 을 한번 visualization 해 봅시다.\n",
        "\n",
        "*Class Activation Map 이란, Helmet 클래스로 판단하는 데 어떤 부분을 가장 주목해서 보았는지와 같이, 어떤 클래스로 판단하는 것의 근거를 Visualization 한 이미지를 의미합니다. "
      ]
    }
  ]
}